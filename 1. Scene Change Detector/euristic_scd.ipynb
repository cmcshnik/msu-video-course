{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кольцов Кирилл Евгеньевич, ВМК МГУ, группа 209, 2025\n",
    "Эвристический детектор смены сцен в видео на основе ансамбля трёх метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весь блок ниже - функции, скопированные из предоставленного шаблона задания, обеспечивающие чтение и оценку точности детектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Для установки opencv воспользуйтесь командой в терминале conda install -c conda-forge opencv\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f, strict=False)\n",
    "\n",
    "\n",
    "def dump_json_to_file(obj, filename, **kwargs):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(obj, f, **kwargs)\n",
    "\n",
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        yield frame\n",
    "    cap.release()\n",
    "\n",
    "def visualize_metric_error(frame, prev_frame, value):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.suptitle('Значение метрики на текущем кадре: {:.4f}'.format(value), fontsize=24)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(prev_frame[:,:,::-1])\n",
    "    ax.set_title(\"Предыдущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(frame[:,:,::-1])\n",
    "    ax.set_title(\"Текущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "\n",
    "def visualize_metric_values(metric_values, threshold, cuts = None):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(metric_values, label='Значение метрики на кадрах')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Значение метрики')\n",
    "    plt.hlines(y=threshold, xmin=0, xmax=len(metric_values), linewidth=2, color='r', label='Пороговое значение')\n",
    "    \n",
    "    if cuts is not None:\n",
    "        for cut in cuts:\n",
    "            plt.axvline(x=cut, color='k', linestyle=':', linewidth=0.5, label='Смена сцены')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()\n",
    "\n",
    "def calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    predicted_scd = set(predicted_scd)\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    for scd in predicted_scd:\n",
    "        if scd in true_scd:\n",
    "            tp += 1\n",
    "        elif scd not in not_to_use_frames:\n",
    "            fp += 1\n",
    "    for scd in true_scd:\n",
    "        if scd not in predicted_scd:\n",
    "            fn += 1\n",
    "    tn = scene_len - len(not_to_use_frames) - tp - fp - fn\n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fp))\n",
    "\n",
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fn))\n",
    "\n",
    "def f1_score(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)\n",
    "    \n",
    "def f1_score_matrix(tp, fp, tn, fn):\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)\n",
    "    \n",
    "def run_scene_change_detector_all_video(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        # Загружаем видео, его длину и смены сцен\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        # Составляем список сцен, которые не будут тестироваться\n",
    "        not_use_frames = set()\n",
    "        for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "            for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "                not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        \n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        \n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn \n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая ячейка содержит вспомогательную функцию view_as_blocks, которая делит поданный в неё кадр на количество квадратных блоков, равное второму аргументу number_of_blocks в квадрате.\n",
    "Во всех трех метриках используется подобное разбиение, так как оно позволят повысить устойчивость к незначительным изменениям и к движению объектов в кадре. Все дальнейшие расчеты метрик производятся между соответствующими блоками двух соседних кадров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_as_blocks(frame, number_of_blocks):\n",
    "    H, W, C = frame.shape\n",
    "    block_h = H // number_of_blocks   \n",
    "    block_w = W // number_of_blocks \n",
    "\n",
    "    H_cropped = block_h * number_of_blocks\n",
    "    W_cropped = block_w * number_of_blocks\n",
    "    frame = frame[:H_cropped, :W_cropped, :]\n",
    "\n",
    "    blocks = frame.reshape(\n",
    "        number_of_blocks, block_h,\n",
    "        number_of_blocks, block_w,\n",
    "        C\n",
    "    ).transpose(0, 2, 1, 3, 4)\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее представлено описание трёх метрик. \n",
    "Названия главных функций, возвращающих вектор значений, по которым можно судить о смене сцены, имеют структуру calculate_<metric>_vector. Значения в векторе есть ни что иное, как значения метрики для каждого отдельного блока кадра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая из них - DSSIM (structural dissimilarity index measure). Она ориентируется на общие структурные признаки в соседних блоках, считая среднее значение, дисперсию и ковариацию. Из всех трёх на тестовых данных имеет наибольшую точность. (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim_for_blocks(prev_block, block, k1=0.01, k2=0.03, L=255):\n",
    "    block = cv2.cvtColor(block, cv2.COLOR_BGR2GRAY).astype(np.float64)\n",
    "    prev_block = cv2.cvtColor(prev_block, cv2.COLOR_BGR2GRAY).astype(np.float64)\n",
    "\n",
    "    C1 = (k1 * L) ** 2\n",
    "    C2 = (k2 * L) ** 2\n",
    "\n",
    "    mu1 = np.mean(block, axis=(0, 1))\n",
    "    mu2 = np.mean(prev_block, axis=(0, 1))\n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = np.var(block, axis=(0, 1))\n",
    "    sigma2_sq = np.var(prev_block, axis=(0, 1)) \n",
    "    sigma12 = np.mean(block * prev_block, axis=(0, 1)) - mu1_mu2\n",
    "    \n",
    "    numerator = (2 * mu1_mu2 + C1) * (2 * sigma12 + C2)\n",
    "    denominator = (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        ssim = 1.0 if numerator == 0 else 0.0\n",
    "    else:\n",
    "        ssim = numerator / denominator\n",
    "\n",
    "    return ssim\n",
    "\n",
    "\n",
    "def calculate_dssim_vector(prev_frame, frame, number_of_blocks=10):\n",
    "    frame = view_as_blocks(frame, number_of_blocks)\n",
    "    prev_frame = view_as_blocks(prev_frame, number_of_blocks)\n",
    "\n",
    "    dssim_vector = []\n",
    "    \n",
    "    for i in range(0, number_of_blocks):\n",
    "        for j in range(0, number_of_blocks):\n",
    "            block = frame[i, j]\n",
    "            prev_block = prev_frame[i, j]\n",
    "            \n",
    "            block_ssim = compute_ssim_for_blocks(prev_block, block)\n",
    "            \n",
    "            dssim_vector.append((1 - block_ssim) / 2)\n",
    "    \n",
    "    return dssim_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая - на основе преобразования Собеля. Она стремится выявить границы объектов на видео и определить, насколько они изменились между кадрами. Нормализация способствовала приросту точности метрики. \n",
    "\n",
    "Исключена из итогового решения ради увеличения производительности. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_manual(frame):\n",
    "    min_val = np.min(frame)\n",
    "    max_val = np.max(frame)\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(frame, dtype=np.uint8)\n",
    "    \n",
    "    norm = (frame - min_val) * 255.0 / (max_val - min_val)\n",
    "    return norm.astype(np.uint8)\n",
    "\n",
    "def compute_sobel_euclidean(block, ksize=3):\n",
    "    if len(block.shape) == 3:\n",
    "        gray = cv2.cvtColor(block, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = block.copy()\n",
    "    \n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    \n",
    "    sobel = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    sobel_norm = normalize_manual(sobel)\n",
    "\n",
    "    return sobel_norm\n",
    "\n",
    "\n",
    "def calculate_sobel_vector(prev_frame, frame, number_of_blocks=10, ksize=3):\n",
    "    blocks_prev = view_as_blocks(prev_frame, number_of_blocks)\n",
    "    blocks_curr = view_as_blocks(frame, number_of_blocks)\n",
    "    \n",
    "    diff_vector = []\n",
    "    \n",
    "    for i in range(number_of_blocks):\n",
    "        for j in range(number_of_blocks):\n",
    "            block_prev = blocks_prev[i, j]\n",
    "            block_curr = blocks_curr[i, j]\n",
    "            \n",
    "            sobel_prev = compute_sobel_euclidean(block_prev, ksize)\n",
    "            sobel_curr = compute_sobel_euclidean(block_curr, ksize)\n",
    "            \n",
    "            diff = np.abs(sobel_prev.astype(np.int16) - sobel_curr.astype(np.int16))\n",
    "            diff_vector.append(np.mean(diff))\n",
    "    \n",
    "    return diff_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И третья работает с цветовыми гистограммами в пространстве HSV. Она выявляет зависимости в насыщенности, тоне и яркости, а также обладает большей устойчивостью к шумам, в отличие от той же метрики в пространстве RGB. Данный факт описывается в литературе и был подтвержден на практике. \n",
    "Сравнение двух гистограмм происходит по так называемой чи-квадрат метрике. \n",
    "В процессе тестирования было обнаружено, что метрика заметно хуже показывает себя на черно-белых видео. Соответственно проводится одна проверка на цветовую гамму и при необходимости корректируются параметры. (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнивает две гистограммы по чи-квадрат метрике\n",
    "def compare_hist_chi_square(hist1, hist2, eps=1e-10):\n",
    "    h1 = hist1.flatten()\n",
    "    h2 = hist2.flatten()\n",
    "\n",
    "    chi_square = np.sum(((h1 - h2) ** 2) / (h1 + h2 + eps))\n",
    "    return chi_square\n",
    "\n",
    "def normalize_hist_manual(hist, alpha=0, beta=1):\n",
    "    min_val = np.min(hist)\n",
    "    max_val = np.max(hist)\n",
    "    \n",
    "    if max_val - min_val == 0:\n",
    "        return np.full(hist.shape, alpha, dtype=hist.dtype)\n",
    "    \n",
    "    norm_hist = (hist - min_val) * (beta - alpha) / (max_val - min_val) + alpha\n",
    "    return norm_hist\n",
    "\n",
    "def is_grayscale_block(block, tol=1e-5):\n",
    "    return np.allclose(block[:,:,0], block[:,:,1], atol=tol) and np.allclose(block[:,:,1], block[:,:,2], atol=tol)\n",
    "\n",
    "def is_grayscale_frame(frame, number_of_blocks=10):\n",
    "    frame_blocks = view_as_blocks(frame, number_of_blocks)\n",
    "\n",
    "    for i in range(number_of_blocks):\n",
    "        for j in range(number_of_blocks):\n",
    "          if is_grayscale_block(frame_blocks[i][j]):\n",
    "              return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def calculate_hist_vector(prev_frame, frame, hist_gray_frame_flag=False, h_bins=50, s_bins=60, blocks=10):\n",
    "    if not hist_gray_frame_flag:\n",
    "        prev_frame_blocks = view_as_blocks(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV), blocks)\n",
    "        frame_blocks = view_as_blocks(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), blocks)\n",
    "    else:\n",
    "        prev_frame_blocks = view_as_blocks(prev_frame, blocks)\n",
    "        frame_blocks = view_as_blocks(frame, blocks)\n",
    "\n",
    "    hist_vector = []\n",
    "\n",
    "    for i in range(blocks):\n",
    "        for j in range(blocks):\n",
    "            prev_frame_block = prev_frame_blocks[i, j]\n",
    "            frame_block = frame_blocks[i, j]\n",
    "            \n",
    "            if hist_gray_frame_flag:\n",
    "                hist1 = cv2.calcHist([prev_frame_block], [0], None, [256], [0, 256])\n",
    "                hist2 = cv2.calcHist([frame_block], [0], None, [256], [0, 256])\n",
    "            else:\n",
    "                hist1 = cv2.calcHist([prev_frame_block], [0, 1], None, [h_bins, s_bins], [0, 180, 0, 256])\n",
    "                hist2 = cv2.calcHist([frame_block], [0, 1], None, [h_bins, s_bins], [0, 180, 0, 256])\n",
    "            \n",
    "            hist1_norm = normalize_hist_manual(hist1, alpha=0, beta=1)\n",
    "            hist2_norm = normalize_hist_manual(hist2, alpha=0, beta=1)\n",
    "            \n",
    "            corr = compare_hist_chi_square(hist1_norm, hist2_norm)\n",
    "            hist_vector.append(corr)\n",
    "    \n",
    "    return hist_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее идёт основной алгоритм.\n",
    "\n",
    "Главная идея заключается в динамическом вычислении порога по формуле в зависимости от кадров в окне. Под окном подразумеватся группа подряд идущих N кадров, в данном случае N = 10. Сама формула имеет вид: \n",
    "threshold = mean + k * std (*),\n",
    "где mean - это среднее значение последовательности средних значений каждого кадра, посчитанных на основе вектора значений метрики в блоках кадра, std - стандартное отклонение той же последовательности, k - некоторый коэффициент. \n",
    "Далее каждый блок нового кадра сравнивается с посчитанным порогом threshold. Затем считается процент прошедших порог блоков percentage, и это число сравнивается с некоторым фиксированным значением, после чего делается вывод о наличии смены сцены. \n",
    "В случае ансамбля используется метод мягкого голосования soft_vote, где все три метрики вносят свой вклад на основе предварительно посчитанной точности accuracy и процента блоков percentage:\n",
    "soft_vote = (accuracy1 * percentage1 + accuracy2 * percentage2 + accuracy3 * percentage3) / (accuracy1 + accuracy2 + accuracy3). Далее soft_vote сравнивается с установленным порогом и делается вывод о наличии смены сцены.\n",
    "\n",
    "Данный подход эмпирически показал наилучший результат, в отличие от остальных, где: формула (*) считается отдельно для каждой последовательности соответствующих блоков; проверку на преодоление порога проходит не каждый блок нового кадра, а среднее значение посчитанных для его блоков выходов метрик.\n",
    "\n",
    "Кэффициент k = 3 (и k = 13 в случае черно-белого видео для гстограммной метрики) был подобран эмпирически. Данная формула показала хорошие результаты по сравнению с фиксированным глобальным порогом.\n",
    "\n",
    "Сам алгоритм прохождения по видео окном выглядит так: существует переменная remained_frames, которая показывает, сколько кадров не хватает в окне для полной загруженности. Она изначально равно размеру окна, и при первых итерациях уменьшается, тем самым позволяя окну заполняться. Само окно с каждой итерацией пополняется вектором значений метрики, которые были посчитаны между двумя соседними кадрами. Когда remained_frames становится равной нулю, начинаюся расчеты порога, а также голосование, по которому заключается присутствие или отсутствие смены сцены в новом кадре, по сравнению с предыдущими в окне. Если смены не было, то происходит обычное обновление окна. В обратном случае remained_frames сбрасывается до нуля и окно заполняется заново."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены две вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсчет порога по формуле и вычисление вектора блоков, которые порог прошли\n",
    "def get_mask(window, current, k):\n",
    "    mean = np.mean(window, axis=0)\n",
    "    std = np.std(window, axis=0)\n",
    "    threshold = mean + k * std\n",
    "\n",
    "    mask = current > threshold\n",
    "    return mask\n",
    "\n",
    "# Обновление окна\n",
    "def update_window(window, current, number_of_max_elements_in_window):\n",
    "    window.append(current)\n",
    "\n",
    "    if len(window) > number_of_max_elements_in_window:\n",
    "        window.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CELL: scene_change_detector\n",
    "\n",
    "def scene_change_detector(frames, threshold=None, with_vis=False):\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Общие параметры\n",
    "    prev_frame = None\n",
    "    number_of_frames_in_window = 10 \n",
    "    remained_frames = number_of_frames_in_window\n",
    "    global_threshold = 0.6\n",
    "    \n",
    "    # (1)\n",
    "    dssim_window = []\n",
    "    dssim_k = 3\n",
    "    dssim_accuracy = 0.89  # Значения <metric>_accuracy были посчитаны отдельно для каждой метрики \n",
    "\n",
    "    # (2)\n",
    "    sobel_k = 2\n",
    "    sobel_window = []\n",
    "    sobel_accuracy = 0.76\n",
    "\n",
    "    # (3)\n",
    "    hist_window = []\n",
    "    hist_k = 3\n",
    "    hist_grey_k = 13\n",
    "    hist_gray_frame_flag = False\n",
    "    hist_accuracy = 0.80\n",
    "\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        if idx == 0:\n",
    "            prev_frame = frame\n",
    "            continue\n",
    "\n",
    "        # (1)\n",
    "        dssim_current = calculate_dssim_vector(prev_frame, frame)\n",
    "\n",
    "        # (2)\n",
    "        sobel_current = calculate_sobel_vector(prev_frame, frame)\n",
    "\n",
    "        # (3)\n",
    "        if hist_gray_frame_flag or is_grayscale_frame(frame):\n",
    "            hist_gray_frame_flag = True\n",
    "            hist_k = hist_grey_k\n",
    "\n",
    "        hist_current = calculate_hist_vector(prev_frame, frame, hist_gray_frame_flag)\n",
    "\n",
    "        if remained_frames == 0:\n",
    "            dssim_percentage = np.mean(get_mask(dssim_window, dssim_current, dssim_k))\n",
    "            sobel_percentage = np.mean(get_mask(sobel_window, sobel_current, sobel_k))\n",
    "            hist_percentage = np.mean(get_mask(hist_window, hist_current, hist_k))\n",
    "            \n",
    "            soft_vote = 0\n",
    "            soft_vote += dssim_accuracy * dssim_percentage \n",
    "            soft_vote += sobel_accuracy * sobel_percentage \n",
    "            soft_vote += hist_accuracy * hist_percentage \n",
    "            soft_vote /= dssim_accuracy + hist_accuracy\n",
    "\n",
    "            if (soft_vote > global_threshold):\n",
    "                scene_changes.append(idx)\n",
    "            \n",
    "                if with_vis:\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "\n",
    "                remained_frames = number_of_frames_in_window\n",
    "\n",
    "            metric_values.append([dssim_percentage, sobel_percentage, hist_percentage])\n",
    "            metric_values.append([dssim_percentage, hist_percentage])\n",
    "        else:\n",
    "            remained_frames -= 1\n",
    "\n",
    "        update_window(dssim_window, np.mean(dssim_current), number_of_frames_in_window)\n",
    "        update_window(sobel_window, np.mean(sobel_current), number_of_frames_in_window)\n",
    "        update_window(hist_window, np.mean(hist_current), number_of_frames_in_window)\n",
    "            \n",
    "        prev_frame = frame\n",
    "\n",
    "        ###  END CODE HERE  ###\n",
    "        pass\n",
    "\n",
    "    return scene_changes, vis, metric_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
